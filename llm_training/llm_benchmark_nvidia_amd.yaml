name:    llm-nvidia-amd
outpath: llm_benchmark_nvidia_amd_run
comment: llm benchmark jube script for NVIDIA-A100,H100,GH200 and AMD-MI250
# Megatron-LM benchmark for 
  #   JEDI-GH200 NVIDIA Node:
  #   4× NVIDIA GH200 Grace-Hopper Superchip 
  #   CPU: NVIDIA Grace (Arm Neoverse-V2), 72 cores at 3.1 GHz base frequency; 120 GB LPDDR5X memory at 512 GB/s (8532 MHz)
  #   GPU: NVIDIA Hopper H100, 132 multiprocessors, 96 GB HBM3 memory at 4 TB/s
  #     NVIDIA NVLink-C2C CPU-to-GPU link at 900 GB/s
  #   Network: 4× InfiniBand NDR200 (Connect-X7)
  #   TDP: 680 W (for full GH200 superchip)
  #   Available: 44 nodes

  # JURECA-GH200 NVIDIA:
  #   1× NVIDIA GH200 Grace-Hopper Superchip
  #   CPU: 1 × NVIDIA Grace, 72 cores
  #   GPU: 1 × NVIDIA H100
  #   Memory: 480 GiB LPDDR5X and 96 GiB HBM3
  #   Network: 1 × NVIDIA ConnectX-7 @ 2 × EDR (200 Gbit/s)
  #   Available: 1 chip

  # JURECA-WAIH100 NVIDIA Node:
  #   4x NVIDIA H100 Hopper-NVLink
  #   CPU: 2x Intel Xeon Platinum 8462Y (Sapphire Rapids) CPUs
  #    A total of 64 computing cores per node Ã 2.8 GHz (Base Freq.)
  #   Memory: 512 GB DDR5 RAM per node
  #   GPU: 4x NVIDIA H100 GPUs (incl. NVLink Interconnect);94 GB HBM2e per GPU
  #   Available: 16 nodes

  # JURECA-H100 NVIDIA Node:
  #   1× NVIDIA H100 Hopper-PCIe
  #   CPU: Intel Xeon Platinum Sapphire Rapid 8452Y processor; 2 sockets, 36 cores per socket,\
  #    SMT-2 (total: 2×36×2 = 144 threads) (details for Intel Xeon Platinum 8452Y on Intel ARK)
  #   Memory: 512 GiB DDR5-4800 RAM (of which at least 20 GB is taken by the system software stack,\
  #    including the file system); 256 GB per socket;
  #   GPU: 4 × NVIDIA H100 PCIe GPUs, each with 80 GB memory;
  #   Network: 1 × 1x BlueField-2 ConnectX-6 DPU @ EDR (100 Gbit/s)
  #   Available: 1 node

  # JURECA-A100 NVIDIA Node:
  #   4x NVIDIA A100 Ampere-SXM
  #   CPU: 2× AMD EPYC 7742, 2× 64 cores, 2.25 GHz
  #   Memory: 512 (16× 32) GB DDR4, 3200 MHz
  #   GPU: 4× NVIDIA A100 GPU, 4× 40 GB HBM2e
  #   Network: 2× InfiniBand HDR (NVIDIA Mellanox Connect-X6)
  #   Available: 192 nodes

  # JURECA-MI200 AMD Node:
  #  2× AMD MI250
  #  CPU: AMD EPYC 7443 processor (Milan); 2 sockets, 24 cores per socket, 
  #   SMT-2 (total: 2×24×2 = 96 threads) in NPS-4 1 configuration (details for AMD EPYC 7443 on WikiChip)
  #  Memory: 512 GiB DDR4-3200 RAM (of which at least 20 GB is taken by the system software stack, 
  #   including the file system); 256 GB per socket; 8 memory channels per socket (2 channels per NUMA domain)
  #  GPU: 4 × AMD MI250 GPUs, each with 128 GB memory; the GPUs are built as Multi Chip Modules (MCM) 
  #   and because of that they are shown as 8 GPUs with 64 GB memory each.
  #  Network: 1 × Mellanox HDR InfiniBand ConnectX 6 (100 Gbit/s)
  #  Available: 2 nodes

parameterset:
  - name: systemInfo
    parameter:
      - {name: system_name, type: str, tag: "JEDI",    _: "JEDI"}
      - {name: system_name, type: str, tag: "GH200",   _: "GH200"}
      - {name: system_name, type: str, tag: "WAIH100", _: "WAIH100"}
      - {name: system_name, type: str, tag: "H100",    _: "H100"}
      - {name: system_name, type: str, tag: "A100",    _: "A100"}
      - {name: system_name, type: str, tag: "MI250",   _: "MI250"}
      - {name: system_version,         mode: shell,    _: "echo 2024.01"}

  - name: modelParameter
    parameter:
      - {name: llm_model_size,   type: str, tag: "800M",   _: "800M"}
      - {name: llm_model_size,   type: str, tag: "13B",    _: "13B"}
      - {name: llm_model_size,   type: str, tag: "175B",   _: "175B"}
      - {name: model_type,        type: str,               _: "GPT"}
      - {name: modelidx,          type: int, mode: python, _: "{'800M': '0', '13B': '1', '175B': '2'}['$llm_model_size']"}
      - {name: nhidden,           type: int, mode: python, _: "[2048,5120,12288][$modelidx]"}
      - {name: nlayers,           type: int, mode: python, _: "[16,40,96][$modelidx]"}
      - {name: nheads,            type: int, mode: python, _: "[8,32,96][$modelidx]"}
      # tp_size is preferred to be <=gpus_per node, to limit communication overhead
      - {name: tp_size,           type: int, mode: python, _: "[1,2,8][$modelidx]"}
      # pp_size must be a divisor of nlayers
      - {name: pp_size,           type: int, mode: python, _: "[1,2,8][$modelidx]"}
      - {name: dp_size,           type: int, mode: python, _: "int( $total_devices / ($pp_size * $tp_size))"}
      - {name: dataset,           type: str,               _: "OSCAR"}
      - {name: total_devices,            type: int, mode: python, update_mode: step, _: "$gpus_per_node*$nodes"}
      - {name: micro_batch_size,  type: int, mode: python, _: "[4,2,2][$modelidx]"}
      - {name: gas,               type: int, mode: python, _: "[1,64,64][$modelidx]"}
      # global_batch_size has to be divisible by dp_size*micro_batch_size*gas; 
      - {name: global_batch_size, type: int, tag: "800M+!container", seperator: ",", _: "32"}
      #16,32,64,128,256,512,1024,2048,4096
      - {name: global_batch_size, type: int, tag: "!800M", mode: python, 
         _: "int( $dp_size * $micro_batch_size * $gas)"}
      - {name: sequence_length,  type: int,                _: 2048}
      - {name: exit_duration,    type: int,                _: 5}
      - {name: modelargs,             tag: "800M",  mode: text,       _: --fp16}
      - {name: modelargs,             tag: "13B",  mode: text,        _: --ffn-hidden-size 20480 --fp16}
      - {name: modelargs,             tag: "175B", mode: text,        _: --bf16}
      - {name: megatron_repo,              tag: "JEDI|GH200|WAIH100|H100|A100", mode: text, _: Megatron-LM}
      - {name: megatron_repo,              tag: "MI250",                        mode: text, _: Megatron-LM-ROCm}
      - name: optimizerargs
        mode: text
        _: >
          --optimizer adam 
          --adam-beta1 0.9 
          --adam-beta2 0.999 
          --adam-eps 1e-8 
          --lr 1e-4 
          --min-lr 1e-5 
          --lr-decay-style cosine 
          --lr-decay-samples 128_953_125 
          --lr-warmup-samples 216_320 
          --clip-grad 1.0 
          --weight-decay 1e-1 
          --use-distributed-optimizer
      - name: additionalargs
        mode: text
        tag: "JEDI|GH200|WAIH100|H100|A100"
        _: >
          --loss-scale-window 500 
          --hysteresis 2 
          --min-loss-scale 1.0
          --initial-loss-scale 4096 
          --position-embedding-type rope 
          --use-flash-attn 
      - name: additionalargs
        mode: text
        tag: "MI250"
        _: >
          --position-embedding-type rotary
          --attention-head-type multihead 
          --no-gradient-accumulation-fusion 
          --data-impl mmap   
      - name: gptargs
        _: >
          --num-layers $nlayers 
          --hidden-size $nhidden 
          --num-attention-heads $nheads 
          --seq-length $sequence_length 
          --max-position-embeddings $sequence_length 
          --micro-batch-size $micro_batch_size 
          --global-batch-size ${global_batch_size}
          --train-samples 300_000_000 
          --vocab-file $$VOCAB_FILE 
          --merge-file $$MERGE_FILE 
          --tokenizer-type GPT2BPETokenizer 
          --init-method-std 0.0048
          --seed 42 
          --sequence-parallel 
          --recompute-activations 
          --recompute-granularity selective 
          $modelargs 
          $optimizerargs 
          $additionalargs
          --exit-duration-in-mins ${exit_duration}
      - name: outputargs
        _: > 
          --log-interval 5
          --save-interval 200000
          --eval-interval 2000
          --eval-iters 15
          --tensorboard-dir $$TENSORBOARD_PATH
          --tensorboard-queue-size 5
          --log-timers-to-tensorboard
          --log-batch-size-to-tensorboard
          --log-validation-ppl-to-tensorboard 

  - name: systemParameter
    init_with: platform.xml
    parameter:
      - {name: account,         tag: "!WAIH100",          _: "zam"}
      - {name: account,         tag: "WAIH100",           _: "westai0005"}
      - {name: queue,           mode: python,             
       _: "{'JEDI': 'all', 'GH200': 'dc-gh','WAIH100': 'dc-wai','H100': 'dc-h100' ,'A100': 'dc-gpu', 'MI250': 'dc-mi200'}['${system_name}']"}
      - {name: nodes,            type: int, tag: "container",   _: 1}
      - {name: nodes,            type: int, tag: "800M",   _: 1}
      - {name: nodes,            type: int, tag: "13B",    _: 44}
      - {name: nodes,            type: int, tag: "175B",   _: 16}
      - {name: gpus_per_node,    type: int, tag: "!GH200+!MI250+!container", _: 4}
      - {name: gpus_per_node,    type: int, tag: "MI250+!container", _: 8}
      - {name: gpus_per_node,    type: int, tag: "(H100|MI250)+container", _: 1}
      - {name: gpus_per_node,    type: int, tag: "GH200",  _: 1}
      - {name: gres,                        tag: "!MI250", _: "gpu:$gpus_per_node"}
      - {name: taskspernode,     type: int,                _: 1}
      - {name: tasks,            type: int, mode: python, update_mode: step, _: "$taskspernode*$nodes"}
      - {name: threadspertask,  type: int, mode: python, tag: "!container" ,
        _: "{'JEDI': '72', 'GH200': '72','WAIH100': '64','H100': '72', 'A100': '128', 'MI250': '48'}['${system_name}']"}
      - {name: threadspertask,  type: int, mode: python, tag: "container", _: 4}
      - {name: timelimit,        tag: "container",         _: "02:00:00"}
      - {name: timelimit,        tag: "!container",         _: "00:15:00"} # set time limit +4mins than exit_duration
      - {name: oottime,          type: int,                _: 120}
      - {name: ootsignal,        type: int,                _: 12}
      - {name: hint,                                      _: "nomultithread"}
      - {name: outlogfile,                                _: "job.out"}
      - {name: outerrfile,                                _: "job.err"}
      - {name: ready_file,                _: "ready"}
      - {name: error_file,                _: "error"}
      - {name: additional_job_config, mode: text,                     _: "#SBATCH --signal=B:${ootsignal}@${oottime}"}
      - {name: root_dir,            type: str,               _: "$jube_benchmark_home/.."}
      # https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-02.html
      # nvcr.io/nvidia/pytorch:24.02-py3
      - {name: singularity_file, type: str, tag: "JEDI|GH200",
         _: "$root_dir/containers/ngc2402_pytorch23_cuda123_nccl219_py310_arm.sif"}
      # https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-06.html
      # nvcr.io/nvidia/pytorch:24.06-py3
      - {name: singularity_file, type: str, tag: "WAIH100|H100|A100", 
          _: "$root_dir/containers/ngc2406_pytorch24_cuda125_nccl2215_py310.sif"}
      # https://hub.docker.com/layers/rocm/pytorch/rocm6.1.2_ubuntu20.04_py3.9_pytorch_release-2.1.2/images/sha256-e3c1c3cde0886689b139daad7a62ad24af3f292855f683d7b28806ae9f1d2a7e?context=explore
      # rocm6.1.2_ubuntu20.04_py3.9_pytorch_release-2.1.2
      - {name: singularity_file, type: str, tag: "MI250", 
          _: "$root_dir/containers/amd_pytorch21_rocm612_rccl2186_py39.sif"}
      - name: ibcomm
        tag: "!GH200|!MI250"
        _: |
          # setting IB for out of band communication
          export NCCL_SOCKET_IFNAME=ib0
          export GLOO_SOCKET_IFNAME=ib0
      - name: ibcomm
        tag: "GH200|MI250"
        _: ""
      - name: rdzv_conf
        tag: "!JEDI"
        _: >
          --rdzv_conf=is_host=$(if ((SLURM_NODEID)); then echo False; else echo True; fi)
      - name: rdzv_conf
        tag: "JEDI"
        _: >
          --rdzv_conf=is_host=True  
      - name: masteri
        tag: "!JEDI"
        _: |
          MASTER_ADDR="${MASTER_ADDR}i"
      - name: masteri
        tag: "JEDI"
        _: ""
      - name: preprocess
        mode: text
        tag: "!container"
        update_mode: step
        separator: |
        _: |
          echo "START TIME: $(date)"
          echo "Submitted batch job $${SLURM_JOBID}"
          export SRUN_CPUS_PER_TASK=$${SLURM_CPUS_PER_TASK}
          export BENCH_DIR=$jube_benchmark_home
          if [ "$system_name" = "MI250" ]; then
              export ROCM_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
          else
              export CUDA_VISIBLE_DEVICES=0,1,2,3
          fi

          if [ "x$$BENCH_DIR" = "x" ]; then
              echo "BENCH_DIR is not set. Please set it to the llm_training directory of benchmark" >&2
              exit 1
          fi

          # Input data
          VOCAB_FILE="$BENCH_DIR"/aux/tokenizers/gpt2-vocab.json
          MERGE_FILE="$BENCH_DIR"/aux/tokenizers/gpt2-merges.txt

          # Path to a singular, preprocessed dataset.
          LLM_DATA_PATH="$BENCH_DIR"/llm_data/oscar_text_document

          # Output data
          # The main directory you want to store output in.
          BENCH_OUTPUT_DIR="$BENCH_DIR"/output
          export PYTHONPATH="$BENCH_DIR/$megatron_repo":$PYTHONPATH

          [ "x$$DATA_OUTPUT_PATH" = x ] &&  DATA_OUTPUT_PATH="$$BENCH_OUTPUT_DIR"/"$llm_model_size"_model_"$$SLURM_JOB_ID"
          [ "x$$CHECKPOINT_PATH" = x ] && CHECKPOINT_PATH=$$DATA_OUTPUT_PATH/checkpoints
          [ "x$$TENSORBOARD_PATH" = x ] &&  TENSORBOARD_PATH=$$DATA_OUTPUT_PATH/tensorboard
          [ "x$$LOGS_PATH" = x ] &&  LOGS_PATH=$$DATA_OUTPUT_PATH/logs
          mkdir -p $$LOGS_PATH

          OLDDIR=$(pwd)
          cd "$BENCH_DIR/$megatron_repo" || exit 1

          rm -f megatron/fused_kernels/build/lock
          CLEAN_PREV_JIT_BUILD=0
          ((CLEAN_PREV_JIT_BUILD)) && rm -rf megatron/fused_kernels/{build,__pycache__}

          MASTER_ADDR="$$(scontrol show hostnames "$$SLURM_JOB_NODELIST" | head -n 1)"
          $masteri
          MASTER_PORT=6000
          export LAUNCHER="python fixed_torch_run.py \
              --nproc_per_node $gpus_per_node \
              --nnodes $nodes \
              --rdzv_endpoint $MASTER_ADDR:$MASTER_PORT \
              --rdzv_backend c10d \
              --max_restarts 0 \
              --node_rank $SLURM_PROCID \
              $rdzv_conf \
              --tee 3 \
              "
          export CMD=" \
              $(pwd)/pretrain_gpt.py \
              --tensor-model-parallel-size $tp_size \
              --pipeline-model-parallel-size $pp_size \
              $gptargs \
              $outputargs \
              --save $CHECKPOINT_PATH \
              --data-path $LLM_DATA_PATH \
              --split 7,3,1 \
              --distributed-backend nccl \
              "
          if [ "$LOAD_CHECKPOINTS" = true ] ; then
              export CMD="$CMD\
                  --load $CHECKPOINT_PATH \
                  "
          fi
          # Necessary for some Megatron-LM settings. We set it all the time just
          # to be safe.
          export CUDA_DEVICE_MAX_CONNECTIONS=1
          export HF_DATASETS_OFFLINE=1
          export TRANSFORMERS_OFFLINE=1

          # With CUDA_LAUNCH_BLOCKING=1, NCCL/2.12.7-1-CUDA-11.5 is needed
          # since NCCL/2.14.3-1-CUDA-11.5 and later versions cause internal streams clashes
          # export CUDA_LAUNCH_BLOCKING=1

          # force crashing on nccl issues like hanging broadcast
          export TORCH_NCCL_ASYNC_ERROR_HANDLING=1

          $ibcomm
          
          # handle timeouts
          export NCCL_IB_TIMEOUT=50
          export UCX_RC_TIMEOUT=4s
          export NCCL_IB_RETRY_CNT=10

          # NCCL and Torch debug
          export LOGLEVEL=INFO 
          # export NCCL_DEBUG=INFO
          # export NCCL_DEBUG_SUBSYS=ALL
          # export TORCH_DISTRIBUTED_DEBUG=INFO
          export TORCHELASTIC_ERROR_FILE=/tmp/torch-elastic-error.json
          
          # for using pre-installed kernels
          export DS_BUILD_OPS=1

          function oothandler {
              echo Received out-of-time signal, creating file "$ready_file" and exiting at $(date) with oottime "$oottime"
              touch $OLDDIR/$ready_file
              exit $ootsignal
          }
          # Trap out-of-time signal to create the error file
          trap oothandler $ootsignal
      - name: variable_export
        mode: shell
        separator: "!"
        _: |
           echo "export BENCH_DIR=${jube_benchmark_home}"
           echo "export ACCELERATOR=$system_name"
           echo "export ENERGY_PATH=${jube_benchmark_home}/${jube_wp_relpath}/${system_name}_power.csv"
      - {name: measurement,  _: $variable_export}
      - name: executable
        mode: python
        separator: ";"
        tag: "!container+!MI250"
        update_mode: step
        _:
          "{'benchmark': \" \\\"$$LAUNCHER $$CMD\\\" 2>&1 | tee -a \\\"$$LOGS_PATH\\\"/main_log.txt & \\nwait\\ncd $$OLDDIR\", 'combine_energy': ''}['$jube_step_name']"
      - name: executable
        mode: python
        separator: ";"
        tag: "!container+MI250"
        update_mode: step
        _:
          "{'benchmark': \" \\\"$$LAUNCHER $$CMD\\\" 2>&1 | tee -a \\\"$$LOGS_PATH\\\"/main_log.txt & \\nwait\\ncd $$OLDDIR\", 'combine_energy': ''}['$jube_step_name']"
      - name: executable
        mode: python
        separator: "!"
        tag: "container"
        update_mode: step
        _: 
          "{'get_container': 'bash  ${jube_benchmark_home}/get_pytorch_container.sh'}['$jube_step_name']"

  - name: executeset
    init_with: platform.xml
    parameter:
      - name: args_starter
        mode: text
        tag: "JEDI+!container"
        separator: |
        _: |
          --cpu_bind=v --mpi=pmi2 apptainer exec  --bind=${jube_benchmark_home} --nv ${singularity_file} ${jube_benchmark_home}/nvidia_arm_torch_wrap.sh
      - name: args_starter
        mode: text
        tag: "!(JEDI|MI250|GH200|H100)+!container"
        separator: |
        _: |
          --disable-dcgm --cpu_bind=v --mpi=pspmix env PMIX_SECURITY_MODE=native apptainer exec --bind=${jube_benchmark_home} --nv ${singularity_file} ${jube_benchmark_home}/nvidia_x86_torch_wrap.sh
      - name: args_starter
        mode: text
        tag: "(GH200|H100)+!container"
        separator: |
        _: |
          --cpu_bind=v --mpi=pspmix env PMIX_SECURITY_MODE=native apptainer exec --bind=${jube_benchmark_home} --nv ${singularity_file} ${jube_benchmark_home}/nvidia_arm_torch_wrap.sh
      - name: args_starter
        mode: text
        tag: "MI250+!container"
        separator: |
        _: |
          --cpu_bind=none,v --mpi=pspmix env PMIX_SECURITY_MODE=native apptainer exec --bind=${jube_benchmark_home} ${singularity_file} ${jube_benchmark_home}/amd_torch_wrap.sh

patternset:
   - name: perf_patterns
     pattern:
      - {name: jobid,      type: int, _: "Submitted batch job $jube_pat_int" }
      - {name: iter_pat,   type: int, _: "iteration\\s+$jube_pat_int/\\s*$jube_pat_nint"}
      - {name: iterations, type: int, mode: python, _: "$iter_pat_max"}
      - {name: tflops_pat, type: float, _: "TFLOPs:\\s+$jube_pat_fp"}
      # https://github.com/NVIDIA/Megatron-LM/blob/f7727433293427bef04858f67b2889fe9b177d88/megatron/training.py#L598
      # https://github.com/bigcode-project/Megatron-LM/blob/21045b59127cd2d5509f1ca27d81fae7b485bd22/megatron/training.py#L616
      - {name: elp_pat,    type: float, _: "elapsed time per iteration \\(s\\):\\s+$jube_pat_fp"}
      - {name: tokens_per_second,  type: float,  mode: python, _: "(1.0/$elp_pat_avg)*$global_batch_size*$sequence_length"}
      - {name: throughput_in_time, type: float, mode: python, _: "(20000000/$tokens_per_second)"}
      #- {name: energy_list_reimann,type: str,   _: "Energy-per-GPU-list integrated\\(Wh\\): (\\[.*?\\])"}
      #- {name: energy_list_counter,type: str, tag: "MI250",  _: "Energy-per-GPU-list from counter\\(Wh\\): (\\[.*?\\])"}
   - name: efile_patterns
     pattern:
      - {name: energy_file_path, type: str, _: "Writing combined energy DataFrame to (.*)"}
analyser:
  - name: analyse
    reduce: false
    analyse:
      - step: combine_energy
        file:
          {use: efile_patterns, _: stdout}
      - step: benchmark
        file:
          {use: perf_patterns, _: job.out}

result:
    use:
      - analyse
    table:
      name: result
      style: csv
      sort: iter_pat
      column: 
        - {title: "JobID", _: jobid}
        - {title: "System", _: system_name}
        - {title: "Version", _: system_version}
        - {title: "Queue", _: queue}
        - {title: "JobTime", _: timelimit}
        - {title: "Runtime(min)", _: exit_duration}
        - {title: "Model", _: model_type}
        - {title: "ModelSize", _: llm_model_size}
        - {title: "Dataset", _: dataset}
        - {title: "Nodes", _: nodes}
        - {title: "Devices", _: total_devices}
        - {title: "GlobalBatchSize", _: global_batch_size}
        - {title: "PipelineParallel", _: pp_size}
        - {title: "TensorParallel", _: tp_size}
        - {title: "DataParallel", _: dp_size}
        - {title: "Iterations", _: iterations}
        # - {title: "TFLOPs logged", _: tflops_pat_cnt}
        - {title: "Time/iteration(s)", format: ".2f", _: elp_pat_avg}
        - {title: "Tokens/second",format: ".2f", _: tokens_per_second}
        - {title: "Avg_TFLOPs/GPU", format: ".2f", _: tflops_pat_avg}
        - {title: "EnergyFile",  _: energy_file_path}
        # - {title: "Energy/Device(Wh)",  _: energy_list_reimann}
        # - {title: "Energy_counter/Device(Wh)", tag: "MI250",  _: energy_list_counter}
        # - {title: "time_to_report_in_seconds",format: ".2f", _: throughput_in_time}

step:

    - name: get_container
      tag: container+(H100|GH200|MI250)
      iterations: 1
      use:
        - systemInfo
        - systemParameter
        - executeset
        - from: platform.xml
          _: jobfiles
        - from: platform.xml
          _: executesub
      do:
        done_file:  $ready_file
        error_file: $error_file
        _:          $submit $submit_script     

    - name: setup_llm
      tag: "!MI250+!container"
      iterations: 1
      use:
        - systemInfo
      do:
        - export BENCH_DIR=$jube_benchmark_home
        - export ACCELERATOR=$system_name
        - bash $BENCH_DIR/setup_nvidia_llm.sh
    - name: setup_llm
      tag: "MI250+!container"
      iterations: 1
      do:
        - export BENCH_DIR=$jube_benchmark_home
        - bash $BENCH_DIR/setup_amd_llm.sh

    - name: benchmark
      tag: "!container"
      iterations: 1
      depend: setup_llm
      use:
        - systemInfo
        - systemParameter
        - modelParameter
        - executeset
        - from: platform.xml
          _: jobfiles
        - from: platform.xml
          _: executesub
      do:
          done_file:  $ready_file
          error_file: $error_file
          _:          $submit $submit_script
    - name: combine_energy
      tag: "!container"
      iterations: 1
      depend: benchmark
      use:
        - systemInfo
        - systemParameter
      do:
        - module load GCC SciPy-bundle
        - python3 ${jube_benchmark_home}/aux/combine_energy.py --output ${jube_benchmark_home}/${jube_wp_relpath}/combined_energy.csv $$(printf "${jube_benchmark_home}/${jube_wp_relpath}/benchmark/${system_name}_power.%d.energy.csv " $$(seq 0 $$(($total_devices-1))))

